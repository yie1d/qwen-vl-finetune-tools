{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import torch\n",
    "from transformers import Qwen2_5_VLForConditionalGeneration, AutoProcessor\n",
    "model_path = \"/root/autodl-tmp/ShowUI/model_weight/Qwen2.5-VL-7B-Instruct\"\n",
    "model = Qwen2_5_VLForConditionalGeneration.from_pretrained(model_path, torch_dtype=torch.bfloat16, attn_implementation=\"flash_attention_2\",device_map=\"auto\")\n",
    "processor = AutoProcessor.from_pretrained(model_path)"
   ],
   "id": "70d3ef43cb12dd77"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# @title Plotting Util\n",
    "\n",
    "# Get Noto JP font to display janapese characters\n",
    "!apt-get install fonts-noto-cjk  # For Noto Sans CJK JP\n",
    "\n",
    "#!apt-get install fonts-source-han-sans-jp # For Source Han Sans (Japanese)\n",
    "\n",
    "import json\n",
    "import random\n",
    "import io\n",
    "import ast\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from PIL import ImageColor\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "additional_colors = [colorname for (colorname, colorcode) in ImageColor.colormap.items()]\n",
    "\n",
    "def decode_xml_points(text):\n",
    "    try:\n",
    "        root = ET.fromstring(text)\n",
    "        num_points = (len(root.attrib) - 1) // 2\n",
    "        points = []\n",
    "        for i in range(num_points):\n",
    "            x = root.attrib.get(f'x{i+1}')\n",
    "            y = root.attrib.get(f'y{i+1}')\n",
    "            points.append([x, y])\n",
    "        alt = root.attrib.get('alt')\n",
    "        phrase = root.text.strip() if root.text else None\n",
    "        return {\n",
    "            \"points\": points,\n",
    "            \"alt\": alt,\n",
    "            \"phrase\": phrase\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return None\n",
    "\n",
    "def plot_bounding_boxes(im, bounding_boxes, input_width, input_height):\n",
    "    \"\"\"\n",
    "    Plots bounding boxes on an image with markers for each a name, using PIL, normalized coordinates, and different colors.\n",
    "\n",
    "    Args:\n",
    "        img_path: The path to the image file.\n",
    "        bounding_boxes: A list of bounding boxes containing the name of the object\n",
    "         and their positions in normalized [y1 x1 y2 x2] format.\n",
    "    \"\"\"\n",
    "\n",
    "    # Load the image\n",
    "    img = im\n",
    "    width, height = img.size\n",
    "    print(img.size)\n",
    "    # Create a drawing object\n",
    "    draw = ImageDraw.Draw(img)\n",
    "\n",
    "    # Define a list of colors\n",
    "    colors = [\n",
    "    'red',\n",
    "    'green',\n",
    "    'blue',\n",
    "    'yellow',\n",
    "    'orange',\n",
    "    'pink',\n",
    "    'purple',\n",
    "    'brown',\n",
    "    'gray',\n",
    "    'beige',\n",
    "    'turquoise',\n",
    "    'cyan',\n",
    "    'magenta',\n",
    "    'lime',\n",
    "    'navy',\n",
    "    'maroon',\n",
    "    'teal',\n",
    "    'olive',\n",
    "    'coral',\n",
    "    'lavender',\n",
    "    'violet',\n",
    "    'gold',\n",
    "    'silver',\n",
    "    ] + additional_colors\n",
    "\n",
    "    # Parsing out the markdown fencing\n",
    "    bounding_boxes = parse_json(bounding_boxes)\n",
    "\n",
    "    font = ImageFont.truetype(\"NotoSansCJK-Regular.ttc\", size=14)\n",
    "\n",
    "    try:\n",
    "      json_output = ast.literal_eval(bounding_boxes)\n",
    "    except Exception as e:\n",
    "      end_idx = bounding_boxes.rfind('\"}') + len('\"}')\n",
    "      truncated_text = bounding_boxes[:end_idx] + \"]\"\n",
    "      json_output = ast.literal_eval(truncated_text)\n",
    "    print(json_output)\n",
    "    # Iterate over the bounding boxes\n",
    "    for i, bounding_box in enumerate(json_output):\n",
    "      # Select a color from the list\n",
    "      color = colors[i % len(colors)]\n",
    "\n",
    "      # Convert normalized coordinates to absolute coordinates\n",
    "      abs_y1 = int(bounding_box[\"bbox_2d\"][1]/input_height * height)\n",
    "      abs_x1 = int(bounding_box[\"bbox_2d\"][0]/input_width * width)\n",
    "      abs_y2 = int(bounding_box[\"bbox_2d\"][3]/input_height * height)\n",
    "      abs_x2 = int(bounding_box[\"bbox_2d\"][2]/input_width * width)\n",
    "\n",
    "      if abs_x1 > abs_x2:\n",
    "        abs_x1, abs_x2 = abs_x2, abs_x1\n",
    "\n",
    "      if abs_y1 > abs_y2:\n",
    "        abs_y1, abs_y2 = abs_y2, abs_y1\n",
    "\n",
    "      # Draw the bounding box\n",
    "      draw.rectangle(\n",
    "          ((abs_x1, abs_y1), (abs_x2, abs_y2)), outline=color, width=4\n",
    "      )\n",
    "\n",
    "      # Draw the text\n",
    "      if \"label\" in bounding_box:\n",
    "        draw.text((abs_x1 + 8, abs_y1 + 6), bounding_box[\"label\"], fill=color, font=font)\n",
    "\n",
    "    # Display the image\n",
    "    img.show()\n",
    "\n",
    "\n",
    "def plot_points(im, text, input_width, input_height):\n",
    "  img = im\n",
    "  width, height = img.size\n",
    "  draw = ImageDraw.Draw(img)\n",
    "  colors = [\n",
    "    'red', 'green', 'blue', 'yellow', 'orange', 'pink', 'purple', 'brown', 'gray',\n",
    "    'beige', 'turquoise', 'cyan', 'magenta', 'lime', 'navy', 'maroon', 'teal',\n",
    "    'olive', 'coral', 'lavender', 'violet', 'gold', 'silver',\n",
    "  ] + additional_colors\n",
    "  xml_text = text.replace('```xml', '')\n",
    "  xml_text = xml_text.replace('```', '')\n",
    "  data = decode_xml_points(xml_text)\n",
    "  if data is None:\n",
    "    img.show()\n",
    "    return\n",
    "  points = data['points']\n",
    "  description = data['phrase']\n",
    "\n",
    "  font = ImageFont.truetype(\"NotoSansCJK-Regular.ttc\", size=14)\n",
    "\n",
    "  for i, point in enumerate(points):\n",
    "    color = colors[i % len(colors)]\n",
    "    abs_x1 = int(point[0])/input_width * width\n",
    "    abs_y1 = int(point[1])/input_height * height\n",
    "    radius = 2\n",
    "    draw.ellipse([(abs_x1 - radius, abs_y1 - radius), (abs_x1 + radius, abs_y1 + radius)], fill=color)\n",
    "    draw.text((abs_x1 + 8, abs_y1 + 6), description, fill=color, font=font)\n",
    "  \n",
    "  img.show()\n",
    "  \n",
    "\n",
    "# @title Parsing JSON output\n",
    "def parse_json(json_output):\n",
    "    # Parsing out the markdown fencing\n",
    "    lines = json_output.splitlines()\n",
    "    for i, line in enumerate(lines):\n",
    "        if line == \"```json\":\n",
    "            json_output = \"\\n\".join(lines[i+1:])  # Remove everything before \"```json\"\n",
    "            json_output = json_output.split(\"```\")[0]  # Remove everything after the closing \"```\"\n",
    "            break  # Exit the loop once \"```json\" is found\n",
    "    return json_output"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def inference(img_url, prompt, system_prompt=\"You are a helpful assistant\", max_new_tokens=1024):\n",
    "  image = Image.open(img_url)\n",
    "  messages = [\n",
    "    {\n",
    "      \"role\": \"system\",\n",
    "      \"content\": system_prompt\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": [\n",
    "        {\n",
    "          \"type\": \"text\",\n",
    "          \"text\": prompt\n",
    "        },\n",
    "        {\n",
    "          \"image\": img_url\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "  ]\n",
    "  text = processor.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "  print(\"input:\\n\",text)\n",
    "  inputs = processor(text=[text], images=[image], padding=True, return_tensors=\"pt\").to('cuda')\n",
    "\n",
    "  output_ids = model.generate(**inputs, max_new_tokens=4096)\n",
    "  generated_ids = [output_ids[len(input_ids):] for input_ids, output_ids in zip(inputs.input_ids, output_ids)]\n",
    "  output_text = processor.batch_decode(generated_ids, skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
    "  print(\"output:\\n\",output_text[0])\n",
    "\n",
    "  input_height = inputs['image_grid_thw'][0][1]*14\n",
    "  input_width = inputs['image_grid_thw'][0][2]*14\n",
    "\n",
    "  return output_text[0], input_height, input_width"
   ],
   "id": "7a0fe8f5dcd7f415"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "image_path = \"./assets/spatial_understanding/25795df22868431b861389c0f4ab0ad3.png\"\n",
    "\n",
    "# prompt in chinese\n",
    "prompt = \"\"\"选择客户为泛微上海\"\"\"\n",
    "# prompt in english\n",
    "# prompt = \"Star to favorite.\"\n",
    "\n",
    "## Use a local HuggingFace model to inference.\n",
    "response, input_height, input_width = inference(image_path, prompt, '基于给你的截图，我给你一个操作需求，你给我返回相关操作元素的坐标，以XML格式输出其坐标 <points x y>object</points>')\n",
    "# response, input_height, input_width = inference(image_path, prompt, '基于给你的截图，我给你一个操作需求，你给我返回相关操作元素的坐标，以JSON格式输出其bbox坐标')\n",
    "image = Image.open(image_path)\n",
    "image.thumbnail([640,640], Image.Resampling.LANCZOS)\n",
    "plot_points(image, response, input_width, input_height)"
   ],
   "id": "169503e4eeab4873"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
